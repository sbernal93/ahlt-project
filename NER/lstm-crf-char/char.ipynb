{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Conv1D, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def instances(fi):\n",
    "    xseq = []\n",
    "    yseq = []\n",
    "\n",
    "    for line in fi:\n",
    "        line = line.strip('\\n')\n",
    "        if not line:\n",
    "            # An empty line means the end of a sentence.\n",
    "            # Return accumulated sequences, and reinitialize.\n",
    "            yield xseq, yseq\n",
    "            xseq = []\n",
    "            yseq = []\n",
    "            continue\n",
    "\n",
    "        # Split the line with TAB characters.\n",
    "        fields = line.split('\\t')\n",
    "\n",
    "        # Append the item features to the item sequence.\n",
    "        # fields are:  0=sid, 1=form, 2=span_start, 3=span_end, 4=tag, 5...N = features\n",
    "        item = fields[5:]\n",
    "        xseq.append(item)\n",
    "\n",
    "        # Append the label to the label sequence.\n",
    "        yseq.append(fields[4])\n",
    "    #return xseq, yseq\n",
    "\n",
    "def load_data(fi):\n",
    "    xtrain = []\n",
    "    ytrain = []\n",
    "\n",
    "    for line in fi:\n",
    "        line = line.strip('\\n')\n",
    "        if not line:\n",
    "            continue\n",
    "        # Split the line with TAB characters.\n",
    "        fields = line.split('\\t')\n",
    "\n",
    "        # Append the item features to the item sequence.\n",
    "        # fields are:  0=sid, 1=form, 2=span_start, 3=span_end, 4=tag, 5...N = features\n",
    "        item = fields[5:]\n",
    "        xtrain.append(item)\n",
    "\n",
    "        # Append the label to the label sequence.\n",
    "        ytrain.append(fields[4])\n",
    "    return xtrain, ytrain\n",
    "\n",
    "def instances_pred(fi):\n",
    "    xseq = []\n",
    "    toks = []\n",
    "\n",
    "    for line in fi:\n",
    "        line = line.strip('\\n')\n",
    "        if not line:\n",
    "            # An empty line means the end of a sentence.\n",
    "            # Return accumulated sequences, and reinitialize.\n",
    "            yield xseq, toks\n",
    "            xseq = []\n",
    "            toks = []\n",
    "            continue\n",
    "\n",
    "        # Split the line with TAB characters.\n",
    "        fields = line.split('\\t')\n",
    "\n",
    "        # Append the item features to the item sequence.\n",
    "        # fields are:  0=sid, 1=form, 2=span_start, 3=span_end, 4=tag, 5...N = features\n",
    "        item = fields[5:]\n",
    "        xseq.append(item)\n",
    "\n",
    "        # Append the label to the label sequence.\n",
    "        toks.append([fields[0],fields[1],fields[2],fields[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "tags = []\n",
    "\n",
    "fi = open('../lstm-crf-glove/results/1/train.cod')\n",
    "\n",
    "# Read sentences from STDIN, and append them to the trainer.\n",
    "for xseq, yseq in instances(fi):\n",
    "    sentences.append(xseq)\n",
    "    tags.append(yseq)\n",
    "fi.close()\n",
    "fi = open('../lstm-crf-glove/results/1/train.cod')\n",
    "(xtrain, ytrain) = load_data(fi)\n",
    "x = pd.DataFrame(xtrain)\n",
    "y = pd.DataFrame(ytrain)[0].values\n",
    "\n",
    "max_len = 75\n",
    "words = list(set(x[0].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words)\n",
    "utags = list(set(y))\n",
    "n_tags = len(utags)\n",
    "\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"PAD\"] = 0\n",
    "tag2idx = {t: i for i, t in enumerate(utags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "\n",
    "docs = [[w[0] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          DT\n",
       "1          JJ\n",
       "2          IN\n",
       "3         VBN\n",
       "4          NN\n",
       "5         WRB\n",
       "6          NN\n",
       "7         VBZ\n",
       "8         VBN\n",
       "9          IN\n",
       "10         JJ\n",
       "11         JJ\n",
       "12         NN\n",
       "13         MD\n",
       "14         VB\n",
       "15        VBN\n",
       "16          .\n",
       "17         DT\n",
       "18         NN\n",
       "19         IN\n",
       "20         NN\n",
       "21         RB\n",
       "22         IN\n",
       "23        VBN\n",
       "24         NN\n",
       "25         NN\n",
       "26         NN\n",
       "27          (\n",
       "28         NN\n",
       "29         CC\n",
       "         ... \n",
       "118334    VBZ\n",
       "118335    VBN\n",
       "118336     IN\n",
       "118337     IN\n",
       "118338     NN\n",
       "118339    VBZ\n",
       "118340    VBN\n",
       "118341     IN\n",
       "118342    NNS\n",
       "118343     RB\n",
       "118344    VBG\n",
       "118345     NN\n",
       "118346    NNS\n",
       "118347      ,\n",
       "118348     NN\n",
       "118349    NNS\n",
       "118350     MD\n",
       "118351     VB\n",
       "118352     RB\n",
       "118353    VBD\n",
       "118354     CC\n",
       "118355     NN\n",
       "118356     IN\n",
       "118357     DT\n",
       "118358     NN\n",
       "118359     NN\n",
       "118360     MD\n",
       "118361     VB\n",
       "118362     JJ\n",
       "118363      .\n",
       "Name: 4, Length: 118364, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, value=word2idx[\"PAD\"], padding='post', truncating='post')\n",
    "\n",
    "Y = [[tag2idx[t] for t in tag ]for tag in tags]\n",
    "Y = pad_sequences(maxlen=max_len, sequences=Y, value=tag2idx[\"PAD\"], padding='post', truncating='post')\n",
    "#Y = [to_categorical(i, num_classes=n_tags) for i in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "max_len_char = 10\n",
    "chars = set([w_i for w in words for w_i in w])\n",
    "n_chars = len(chars)\n",
    "print(n_chars)\n",
    "\n",
    "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char2idx[\"UNK\"] = 1\n",
    "char2idx[\"PAD\"] = 0\n",
    "\n",
    "X_char = []\n",
    "for sentence in sentences:\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PAD\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    X_char.append(np.array(sent_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_in = Input(shape=(max_len,))\n",
    "emb_word = Embedding(input_dim=n_words + 2, output_dim=20,\n",
    "             input_length=max_len, mask_zero=True)(word_in)\n",
    "\n",
    "# input and embeddings for characters\n",
    "char_in = Input(shape=(max_len, max_len_char,))\n",
    "emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=10,\n",
    "                   input_length=max_len_char, mask_zero=True))(char_in)\n",
    "# character LSTM to get word encodings by characters\n",
    "char_enc = TimeDistributed(LSTM(units=20, return_sequences=False,\n",
    "                        recurrent_dropout=0.5))(emb_char)\n",
    "\n",
    "# main LSTM\n",
    "x = concatenate([emb_word, char_enc])\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "main_lstm = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                       recurrent_dropout=0.6))(x)\n",
    "out = TimeDistributed(Dense(n_tags + 1, activation=\"softmax\"))(main_lstm)\n",
    "#crf = CRF(n_tags)  # CRF layer\n",
    "#out = crf(model)  # output\n",
    "\n",
    "model = Model([word_in, char_in], out)\n",
    "#model.compile(optimizer=\"adam\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           (None, 75, 10)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_31 (TimeDistri (None, 75, 10, 10)   820         input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 75, 20)       161100      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_32 (TimeDistri (None, 75, 20)       2480        time_distributed_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 75, 40)       0           embedding_21[0][0]               \n",
      "                                                                 time_distributed_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 75, 40)       0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 75, 100)      36400       spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_33 (TimeDistri (None, 75, 10)       1010        bidirectional_11[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 201,810\n",
      "Trainable params: 201,810\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5107 samples, validate on 568 samples\n",
      "Epoch 1/5\n",
      "5107/5107 [==============================] - 21s 4ms/step - loss: 0.8059 - val_loss: 0.4236\n",
      "Epoch 2/5\n",
      "5107/5107 [==============================] - 17s 3ms/step - loss: 0.3404 - val_loss: 0.2546\n",
      "Epoch 3/5\n",
      "5107/5107 [==============================] - 17s 3ms/step - loss: 0.2115 - val_loss: 0.2026\n",
      "Epoch 4/5\n",
      "5107/5107 [==============================] - 17s 3ms/step - loss: 0.1582 - val_loss: 0.1789\n",
      "Epoch 5/5\n",
      "5107/5107 [==============================] - 17s 3ms/step - loss: 0.1267 - val_loss: 0.1760\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X, np.array(X_char).reshape((len(X_char), max_len, max_len_char))],\n",
    "                    np.array(Y).reshape(len(Y), max_len, 1), batch_size=32, epochs=5,\n",
    "                validation_split=0.1, verbose=1)\n",
    "\n",
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDI-DrugBank.d621.s1|26-35|colestipol|drug\n",
      "\n",
      "DDI-DrugBank.d621.s1|38-51|cholestyramine|drug\n",
      "\n",
      "DDI-DrugBank.d621.s1|71-80|sucralfate|drug\n",
      "\n",
      "DDI-DrugBank.d672.s0|0-6|Digoxin|drug\n",
      "\n",
      "DDI-DrugBank.d672.s0|63-69|digoxin|drug\n",
      "\n",
      "DDI-DrugBank.d672.s1|55-66|theophylline|drug\n",
      "\n",
      "DDI-DrugBank.d672.s2|35-46|theophylline|drug\n",
      "\n",
      "DDI-DrugBank.d672.s2|96-103|caffeine|drug\n",
      "\n",
      "DDI-DrugBank.d672.s3|0-7|Warfarin|drug\n",
      "\n",
      "DDI-DrugBank.d672.s3|70-77|warfarin|drug\n",
      "\n",
      "DDI-DrugBank.d672.s4|0-9|Cimetidine|drug\n",
      "\n",
      "DDI-DrugBank.d672.s4|12-21|Cimetidine|drug\n",
      "\n",
      "DDI-DrugBank.d672.s8|0-9|Probenecid|drug\n",
      "\n",
      "DDI-DrugBank.d672.s8|12-21|Probenecid|drug\n",
      "\n",
      "DDI-DrugBank.d733.s2|68-77|diclofenac|drug\n",
      "\n",
      "DDI-DrugBank.d733.s2|82-90|ibuprofen|drug\n",
      "\n",
      "DDI-DrugBank.d617.s1|0-8|lidocaine|drug\n",
      "\n",
      "DDI-DrugBank.d617.s1|11-19|quinidine|drug\n",
      "\n",
      "DDI-DrugBank.d617.s2|0-10|hydralazine|drug\n",
      "\n",
      "DDI-DrugBank.d617.s3|11-19|dinitrate|drug\n",
      "\n",
      "DDI-DrugBank.d617.s3|22-34|nitroglycerin|drug\n",
      "\n",
      "DDI-DrugBank.d617.s4|0-13|chlorthalidone|drug\n",
      "\n",
      "DDI-DrugBank.d617.s4|16-25|furosemide|drug\n",
      "\n",
      "DDI-DrugBank.d617.s4|28-46|hydrochlorothiazide|drug\n",
      "\n",
      "DDI-DrugBank.d617.s4|49-62|spironolactone|drug\n",
      "\n",
      "DDI-DrugBank.d617.s5|0-8|captopril|drug\n",
      "\n",
      "DDI-DrugBank.d617.s6|0-6|heparin|drug\n",
      "\n",
      "DDI-DrugBank.d617.s6|9-16|warfarin|drug\n",
      "\n",
      "DDI-DrugBank.d617.s6|19-26|diazepam|drug\n",
      "\n",
      "DDI-DrugBank.d617.s6|29-35|insulin|drug\n",
      "\n",
      "DDI-DrugBank.d617.s8|123-132|furosemide|drug\n",
      "\n",
      "DDI-DrugBank.d617.s9|11-20|furosemide|drug\n",
      "\n",
      "DDI-DrugBank.d583.s0|49-63|succinylcholine|drug\n",
      "\n",
      "DDI-DrugBank.d583.s1|83-92|isoflurane|drug\n",
      "\n",
      "DDI-DrugBank.d583.s1|95-102|propofol|drug\n",
      "\n",
      "DDI-DrugBank.d583.s2|102-110|midazolam|drug\n",
      "\n",
      "DDI-DrugBank.d719.s0|18-20|MAO|group\n",
      "\n",
      "DDI-DrugBank.d614.s1|188-199|griseofulvin|drug\n",
      "\n",
      "DDI-DrugBank.d614.s6|106-112|ethanol|drug\n",
      "\n",
      "DDI-DrugBank.d614.s7|52-62|allopurinol|drug\n",
      "\n",
      "DDI-DrugBank.d614.s7|65-79|calcium channel|group\n",
      "\n",
      "DDI-DrugBank.d760.s0|236-247|griseofulvin|drug\n",
      "\n",
      "DDI-DrugBank.d760.s0|266-279|nalidixic acid|drug\n",
      "\n",
      "DDI-DrugBank.d644.s0|142-155|cholestyramine|drug\n",
      "\n",
      "DDI-DrugBank.d644.s2|84-92|phenytoin|drug\n",
      "\n",
      "DDI-DrugBank.d644.s2|95-102|Dilantin|group\n",
      "\n",
      "DDI-DrugBank.d644.s2|105-117|carbamazepine|drug\n",
      "\n",
      "DDI-DrugBank.d644.s4|106-113|warfarin|drug\n",
      "\n",
      "DDI-DrugBank.d718.s0|51-57|Calcium|group\n",
      "\n",
      "DDI-DrugBank.d718.s0|72-85|Cholestyramine|drug\n",
      "\n",
      "DDI-DrugBank.d718.s0|100-120|magnesium salicylates|drug\n",
      "\n",
      "DDI-DrugBank.d718.s0|123-132|Colestipol|drug\n",
      "\n",
      "DDI-DrugBank.d593.s0|122-128|digoxin|drug\n",
      "\n",
      "DDI-DrugBank.d684.s3|32-43|erythromycin|drug\n",
      "\n",
      "DDI-DrugBank.d684.s3|46-57|itraconazole|drug\n",
      "\n",
      "DDI-DrugBank.d684.s3|60-71|ketoconazole|drug\n",
      "\n",
      "DDI-DrugBank.d684.s3|74-84|fluconazole|drug\n",
      "\n",
      "DDI-DrugBank.d684.s3|87-110|calcium channel blockers|group\n",
      "\n",
      "DDI-DrugBank.d684.s3|116-125|cimetidine|drug\n",
      "\n",
      "DDI-DrugBank.d731.s1|68-76|cisplatin|drug\n",
      "\n",
      "DDI-DrugBank.d767.s2|54-62|phenytoin|drug\n",
      "\n",
      "DDI-DrugBank.d673.s0|113-119|digoxin|drug\n",
      "\n",
      "DDI-DrugBank.d673.s0|124-131|warfarin|drug\n",
      "\n",
      "DDI-DrugBank.d664.s0|60-67|warfarin|drug\n",
      "\n",
      "DDI-DrugBank.d664.s1|11-18|warfarin|drug\n",
      "\n",
      "DDI-DrugBank.d664.s1|67-74|warfarin|drug\n",
      "\n",
      "DDI-DrugBank.d768.s3|100-113|metoclopramide|drug\n",
      "\n",
      "DDI-DrugBank.d768.s5|96-104|cisplatin|drug\n",
      "\n",
      "DDI-DrugBank.d768.s5|107-122|cyclophosphamide|drug\n",
      "\n",
      "DDI-DrugBank.d768.s5|137-147|doxorubicin|drug\n",
      "\n",
      "DDI-DrugBank.d574.s0|158-168|cyclosporin|drug\n",
      "\n",
      "DDI-DrugBank.d574.s0|171-179|phenytoin|drug\n",
      "\n",
      "DDI-DrugBank.d574.s0|185-196|methotrexate|drug\n",
      "\n",
      "DDI-DrugBank.d646.s0|256-264|midazolam|drug\n",
      "\n",
      "DDI-DrugBank.d646.s1|147-163|ethinyl estradiol|drug\n",
      "\n",
      "DDI-DrugBank.d592.s0|17-22|Sodium|drug\n",
      "\n",
      "DDI-DrugBank.d592.s2|0-6|Heparin|drug\n",
      "\n",
      "DDI-DrugBank.d592.s2|54-59|Sodium|drug\n",
      "\n",
      "DDI-DrugBank.d681.s0|18-27|cimetidine|drug\n",
      "\n",
      "DDI-DrugBank.d681.s0|30-36|digoxin|drug\n",
      "\n",
      "DDI-DrugBank.d681.s0|89-100|theophylline|drug\n",
      "\n",
      "DDI-DrugBank.d730.s0|94-103|cimetidine|drug\n",
      "\n",
      "DDI-DrugBank.d701.s1|42-47|kaolin|drug\n",
      "\n",
      "DDI-DrugBank.d701.s1|66-77|Ketoconazole|drug\n",
      "\n",
      "DDI-DrugBank.d701.s1|81-102|Central nervous system|group\n",
      "\n",
      "DDI-DrugBank.d701.s1|149-173|Tricyclic antidepressants|group\n",
      "\n",
      "DDI-DrugBank.d586.s3|32-43|erythromycin|drug\n",
      "\n",
      "DDI-DrugBank.d586.s3|46-57|itraconazole|drug\n",
      "\n",
      "DDI-DrugBank.d586.s3|60-71|ketoconazole|drug\n",
      "\n",
      "DDI-DrugBank.d586.s3|74-84|fluconazole|drug\n",
      "\n",
      "DDI-DrugBank.d586.s3|87-110|calcium channel blockers|group\n",
      "\n",
      "DDI-DrugBank.d586.s3|116-125|cimetidine|drug\n",
      "\n",
      "DDI-DrugBank.d626.s0|0-6|Alcohol|drug\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for xseq,toks in instances_pred(open('../lstm-crf-glove/results/2/test.cod')):\n",
    "    #x = pd.DataFrame(xseq)\n",
    "    x_test_sent = [[word2idx.get(t[0],0) for t in xseq]]\n",
    "    x_test_sent = pad_sequences(maxlen=max_len, sequences=x_test_sent, padding=\"post\", value=n_words-1)\n",
    "    \n",
    "    sentence = [t[0] for t in xseq]\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PAD\"))\n",
    "        sent_seq.append(word_seq)\n",
    "\n",
    "    #prediction = model.predict(np.array([x_test_sent[0]]))[0]\n",
    "    #model.predict([X_word_te,\n",
    "    #                    np.array(X_char_te).reshape((len(X_char_te),\n",
    "    #                                                 max_len, max_len_char))])\n",
    "    x_test_sent = np.array([x_test_sent[0]])\n",
    "    prediction = model.predict([x_test_sent, np.array(sent_seq).reshape((len(x_test_sent), max_len, max_len_char))])[0]\n",
    "    prediction = np.argmax(prediction, axis=-1)\n",
    "    inside = False;\n",
    "    for k in range(0,len(toks)) :\n",
    "        y = utags[prediction[k]]\n",
    "        (sid, form, offS, offE) = toks[k]\n",
    "\n",
    "        if (y[0]==\"B\") :\n",
    "            entity_form = form\n",
    "            entity_start = offS\n",
    "            entity_end = offE\n",
    "            entity_type = y[2:]\n",
    "            inside = True\n",
    "        elif (y[0]==\"I\" and inside) :\n",
    "            entity_form += \" \"+form\n",
    "            entity_end = offE\n",
    "        elif (y[0]==\"O\" and inside) :\n",
    "            #print(sid, entity_start+\"-\"+entity_end, entity_form, entity_type, sep=\"|\")\n",
    "            print(sid + \"|\" + entity_start+\"-\"+entity_end + \"|\" +entity_form + \"|\" +entity_type + \"\\n\")\n",
    "            inside = False\n",
    "\n",
    "    if inside : print(sid + \"|\" + entity_start+\"-\"+entity_end + \"|\" + entity_form + \"|\" + entity_type + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'is',\n",
       " 'possible',\n",
       " 'that',\n",
       " 'concomitant',\n",
       " 'use',\n",
       " 'of',\n",
       " 'other',\n",
       " 'known',\n",
       " 'photosensitizing',\n",
       " 'agents',\n",
       " 'might',\n",
       " 'increase',\n",
       " 'the',\n",
       " 'photosensitivity',\n",
       " 'reaction',\n",
       " 'of',\n",
       " 'actinic',\n",
       " 'keratoses',\n",
       " 'treated',\n",
       " 'with',\n",
       " 'methyl',\n",
       " 'aminolevulinate',\n",
       " 'cream',\n",
       " '.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
